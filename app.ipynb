{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/bigscience-workshop/petals\r\n",
      "  Cloning https://github.com/bigscience-workshop/petals to /tmp/pip-req-build-qg6j88eg\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/bigscience-workshop/petals /tmp/pip-req-build-qg6j88eg\r\n",
      "  Resolved https://github.com/bigscience-workshop/petals to commit 82a97d6e9ea18e79639f375f124c4c83fe1933e8\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: torch>=1.12 in ./venv/lib64/python3.11/site-packages (from petals==2.3.0.dev0) (2.1.0)\r\n",
      "Requirement already satisfied: bitsandbytes==0.41.1 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (0.41.1)\r\n",
      "Requirement already satisfied: accelerate>=0.22.0 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (0.24.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.1 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (0.17.3)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.3 in ./venv/lib64/python3.11/site-packages (from petals==2.3.0.dev0) (0.14.1)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (4.34.1)\r\n",
      "Requirement already satisfied: speedtest-cli==2.1.3 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (2.1.3)\r\n",
      "Requirement already satisfied: pydantic<2.0,>=1.10 in ./venv/lib64/python3.11/site-packages (from petals==2.3.0.dev0) (1.10.13)\r\n",
      "Requirement already satisfied: hivemind==1.1.10.post2 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (1.1.10.post2)\r\n",
      "Requirement already satisfied: tensor-parallel==1.0.23 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (1.0.23)\r\n",
      "Requirement already satisfied: humanfriendly in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (10.0)\r\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (4.0.3)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (23.2)\r\n",
      "Requirement already satisfied: sentencepiece>=0.1.99 in ./venv/lib64/python3.11/site-packages (from petals==2.3.0.dev0) (0.1.99)\r\n",
      "Requirement already satisfied: peft>=0.5.0 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (0.5.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib64/python3.11/site-packages (from petals==2.3.0.dev0) (0.4.0)\r\n",
      "Requirement already satisfied: Dijkstar>=2.6.0 in ./venv/lib/python3.11/site-packages (from petals==2.3.0.dev0) (2.6.0)\r\n",
      "Requirement already satisfied: cpufeature>=0.2.0 in ./venv/lib64/python3.11/site-packages (from petals==2.3.0.dev0) (0.2.1)\r\n",
      "Requirement already satisfied: PyYAML in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (6.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.26.1)\r\n",
      "Requirement already satisfied: scipy>=1.2.1 in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.11.3)\r\n",
      "Requirement already satisfied: prefetch-generator>=1.0.1 in ./venv/lib/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.0.3)\r\n",
      "Requirement already satisfied: msgpack>=0.5.6 in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.0.7)\r\n",
      "Requirement already satisfied: sortedcontainers in ./venv/lib/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (2.4.0)\r\n",
      "Requirement already satisfied: uvloop>=0.14.0 in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (0.19.0)\r\n",
      "Requirement already satisfied: grpcio-tools>=1.33.2 in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.59.2)\r\n",
      "Requirement already satisfied: protobuf>=3.12.2 in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (4.24.4)\r\n",
      "Requirement already satisfied: configargparse>=1.2.3 in ./venv/lib/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.7)\r\n",
      "Requirement already satisfied: multiaddr>=0.0.9 in ./venv/lib/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (0.0.9)\r\n",
      "Requirement already satisfied: pymultihash>=0.8.2 in ./venv/lib/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (0.8.2)\r\n",
      "Requirement already satisfied: cryptography>=3.4.6 in ./venv/lib64/python3.11/site-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev0) (41.0.5)\r\n",
      "Requirement already satisfied: psutil in ./venv/lib64/python3.11/site-packages (from accelerate>=0.22.0->petals==2.3.0.dev0) (5.9.6)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.11/site-packages (from Dijkstar>=2.6.0->petals==2.3.0.dev0) (1.16.0)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (2023.10.0)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (1.12)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (3.1.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib64/python3.11/site-packages (from torch>=1.12->petals==2.3.0.dev0) (2.1.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12->petals==2.3.0.dev0) (12.3.52)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib64/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->petals==2.3.0.dev0) (2023.10.3)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib64/python3.11/site-packages (from cryptography>=3.4.6->hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio>=1.59.2 in ./venv/lib64/python3.11/site-packages (from grpcio-tools>=1.33.2->hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.59.2)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from grpcio-tools>=1.33.2->hivemind==1.1.10.post2->petals==2.3.0.dev0) (68.2.0)\r\n",
      "Requirement already satisfied: varint in ./venv/lib/python3.11/site-packages (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals==2.3.0.dev0) (1.0.2)\r\n",
      "Requirement already satisfied: base58 in ./venv/lib/python3.11/site-packages (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals==2.3.0.dev0) (2.1.1)\r\n",
      "Requirement already satisfied: netaddr in ./venv/lib/python3.11/site-packages (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals==2.3.0.dev0) (0.9.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib64/python3.11/site-packages (from jinja2->torch>=1.12->petals==2.3.0.dev0) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib64/python3.11/site-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (3.3.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev0) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.11/site-packages (from sympy->torch>=1.12->petals==2.3.0.dev0) (1.3.0)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind==1.1.10.post2->petals==2.3.0.dev0) (2.21)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.11/site-packages (0.0.327)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib64/python3.11/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib64/python3.11/site-packages (from langchain) (2.0.22)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib64/python3.11/site-packages (from langchain) (3.8.6)\r\n",
      "Requirement already satisfied: anyio<4.0 in ./venv/lib/python3.11/site-packages (from langchain) (3.7.1)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.11/site-packages (from langchain) (0.6.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.11/site-packages (from langchain) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in ./venv/lib/python3.11/site-packages (from langchain) (0.0.56)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in ./venv/lib64/python3.11/site-packages (from langchain) (1.26.1)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./venv/lib64/python3.11/site-packages (from langchain) (1.10.13)\r\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.11/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./venv/lib/python3.11/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib64/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/bigscience-workshop/petals\n",
    "%pip install --upgrade langchain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:04:08.259802104Z",
     "start_time": "2023-11-01T20:03:55.757337449Z"
    }
   },
   "id": "5193396351fc1ae1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from transformers import AutoTokenizer\n",
    "from petals import AutoDistributedModelForCausalLM\n",
    "from langchain.llms.base import LLM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:04:08.260699018Z",
     "start_time": "2023-11-01T20:04:08.255655842Z"
    }
   },
   "id": "f126c8f3887df09c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    def __init__(self, model_name: str,max_tokens: int = 15, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, add_bos_token=False)\n",
    "        model = AutoDistributedModelForCausalLM.from_pretrained(model_name)\n",
    "        model = model.cuda()  # Move the model to GPU if available\n",
    "        object.__setattr__(self, \"tokenizer\", tokenizer)\n",
    "        object.__setattr__(self, \"model\", model)\n",
    "        object.__setattr__(self, \"max_tokens\", max_tokens)\n",
    "\n",
    "    def _call(self, text: str, stop=None, **kwargs) -> str:\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")[\"input_ids\"].cuda()\n",
    "        outputs = self.model.generate(inputs, max_new_tokens=self.max_tokens)\n",
    "        decoded_output = (self.tokenizer.decode(outputs[0]))\n",
    "        return decoded_output\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"CustomLLM\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:04:08.301277374Z",
     "start_time": "2023-11-01T20:04:08.259679082Z"
    }
   },
   "id": "4b973ed70b09ee02"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nov 02 01:34:10.268 [\u001B[1m\u001B[34mINFO\u001B[0m] Make sure you follow the LLaMA's terms of use: https://bit.ly/llama2-license for LLaMA 2, https://bit.ly/llama-license for LLaMA 1\n",
      "Nov 02 01:34:10.269 [\u001B[1m\u001B[34mINFO\u001B[0m] Using DHT prefix: StableBeluga2-hf\n",
      "torch_shm_manager: error while loading shared libraries: libcupti.so.12: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "no response from torch_shm_manager at \"/home/biscuitbobby/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/bin/torch_shm_manager\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mCustomLLM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpetals-team/StableBeluga2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 5\u001B[0m, in \u001B[0;36mCustomLLM.__init__\u001B[0;34m(self, model_name, max_tokens, **kwargs)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m      4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name, use_fast\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, add_bos_token\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoDistributedModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mcuda()  \u001B[38;5;66;03m# Move the model to GPU if available\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m, tokenizer)\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/petals/utils/auto_config.py:78\u001B[0m, in \u001B[0;36mDefaultRevisionMixin.from_pretrained\u001B[0;34m(cls, model_name_or_path, revision, *args, **kwargs)\u001B[0m\n\u001B[1;32m     76\u001B[0m     revision \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mDEFAULT_REVISIONS[model_name_or_path]\n\u001B[1;32m     77\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, revision \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 78\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/petals/utils/auto_config.py:51\u001B[0m, in \u001B[0;36m_AutoDistributedBase.from_pretrained\u001B[0;34m(cls, model_name_or_path, *args, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m proper_cls \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPetals does not have \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for model type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39mmodel_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mproper_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/petals/client/from_pretrained.py:31\u001B[0m, in \u001B[0;36mFromPretrainedMixin.from_pretrained\u001B[0;34m(cls, model_name_or_path, low_cpu_mem_usage, *args, **kwargs)\u001B[0m\n\u001B[1;32m     28\u001B[0m     low_cpu_mem_usage \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ignore_keys(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_keys_to_ignore_on_load_unexpected):\n\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/transformers/modeling_utils.py:3085\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3082\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001B[38;5;241m=\u001B[39mtorch_dtype, device_map\u001B[38;5;241m=\u001B[39mdevice_map)\n\u001B[1;32m   3084\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[0;32m-> 3085\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3087\u001B[0m \u001B[38;5;66;03m# Check first if we are `from_pt`\u001B[39;00m\n\u001B[1;32m   3088\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_keep_in_fp32_modules:\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/petals/models/llama/model.py:132\u001B[0m, in \u001B[0;36mDistributedLlamaForCausalLM.__init__\u001B[0;34m(self, config)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, config: DistributedLlamaConfig):\n\u001B[1;32m    131\u001B[0m     LlamaPreTrainedModel\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, config)\n\u001B[0;32m--> 132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mDistributedLlamaModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpretraining_tp \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mpretraining_tp\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab_size \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mvocab_size\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/petals/models/llama/model.py:34\u001B[0m, in \u001B[0;36mDistributedLlamaModel.__init__\u001B[0;34m(self, config, dht)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     32\u001B[0m config\u001B[38;5;241m.\u001B[39mnum_hidden_layers \u001B[38;5;241m=\u001B[39m n_layer\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers \u001B[38;5;241m=\u001B[39m \u001B[43mRemoteSequential\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdht\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdht\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# Forbid accumulate grads for embeddings and layernorm\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_prompts(config)\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/petals/client/remote_sequential.py:47\u001B[0m, in \u001B[0;36mRemoteSequential.__init__\u001B[0;34m(self, config, sequence_manager, dht, start_block, end_block, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m         end_block \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers\n\u001B[1;32m     46\u001B[0m     block_uids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39mdht_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mUID_DELIMITER\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(start_block, end_block))\n\u001B[0;32m---> 47\u001B[0m     sequence_manager \u001B[38;5;241m=\u001B[39m \u001B[43mRemoteSequenceManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblock_uids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdht\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdht\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msequence_manager \u001B[38;5;241m=\u001B[39m sequence_manager\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_active_session \u001B[38;5;241m=\u001B[39m ContextVar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactive_session\u001B[39m\u001B[38;5;124m\"\u001B[39m, default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/petals/client/routing/sequence_manager.py:89\u001B[0m, in \u001B[0;36mRemoteSequenceManager.__init__\u001B[0;34m(self, config, block_uids, dht, state)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m state\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dht \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 89\u001B[0m     dht \u001B[38;5;241m=\u001B[39m \u001B[43mDHT\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43minitial_peers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitial_peers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclient_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstartup_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdaemon_startup_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dht, DHT) \u001B[38;5;129;01mand\u001B[39;00m dht\u001B[38;5;241m.\u001B[39mis_alive(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`dht` must be a running hivemind.DHT instance\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdht \u001B[38;5;241m=\u001B[39m dht\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/hivemind/dht/dht.py:77\u001B[0m, in \u001B[0;36mDHT.__init__\u001B[0;34m(self, initial_peers, start, p2p, daemon, num_workers, record_validators, shutdown_timeout, await_ready, **kwargs)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_pipe, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outer_pipe \u001B[38;5;241m=\u001B[39m mp\u001B[38;5;241m.\u001B[39mPipe(duplex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshutdown_timeout \u001B[38;5;241m=\u001B[39m shutdown_timeout\n\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ready \u001B[38;5;241m=\u001B[39m \u001B[43mMPFuture\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m daemon\n\u001B[1;32m     80\u001B[0m \u001B[38;5;66;03m# These values will be fetched from the child process when requested\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/hivemind/utils/mpfuture.py:101\u001B[0m, in \u001B[0;36mMPFuture.__init__\u001B[0;34m(self, use_lock)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_initialize_mpfuture_backend()\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_origin_pid, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_uid \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetpid(), uuid\u001B[38;5;241m.\u001B[39muuid4()\u001B[38;5;241m.\u001B[39mint\n\u001B[0;32m--> 101\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shared_state_code \u001B[38;5;241m=\u001B[39m \u001B[43mSharedBytes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state_cache: Dict[State, State] \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m# mapping from global to cached local future used that makes updates immediately\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# available on setter side; dictionary-based cache works because future can visit any state at most once\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib/python3.11/site-packages/hivemind/utils/mpfuture.py:60\u001B[0m, in \u001B[0;36mSharedBytes.next\u001B[0;34m(cls)\u001B[0m\n\u001B[1;32m     58\u001B[0m     buffer_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHIVEMIND_SHM_BUFFER_SIZE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m16\u001B[39m))\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_pid \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetpid()\n\u001B[0;32m---> 60\u001B[0m     \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint8\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshare_memory_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_index \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/_tensor.py:684\u001B[0m, in \u001B[0;36mTensor.share_memory_\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    683\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39mshare_memory_, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 684\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_typed_storage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_share_memory_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/storage.py:858\u001B[0m, in \u001B[0;36mTypedStorage._share_memory_\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_share_memory_\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 858\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_untyped_storage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshare_memory_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/storage.py:297\u001B[0m, in \u001B[0;36m_share_memory_lock_protected.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;66;03m# If we acquired the storage lock here and we're done working on it\u001B[39;00m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;66;03m# we can now release it and free the entry.\u001B[39;00m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m to_free \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    302\u001B[0m         \u001B[38;5;66;03m# Ensure that the cdata from the storage didn't change and only\u001B[39;00m\n\u001B[1;32m    303\u001B[0m         \u001B[38;5;66;03m# the data_ptr did.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/storage.py:326\u001B[0m, in \u001B[0;36mUntypedStorage.share_memory_\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;129m@_share_memory_lock_protected\u001B[39m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshare_memory_\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshare_memory_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/storage.py:247\u001B[0m, in \u001B[0;36m_StorageBase.share_memory_\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# CUDA or PrivateUse1 doesn't use POSIX shared memory\u001B[39;00m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m get_sharing_strategy() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfile_system\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 247\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_share_filename_cpu_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_share_fd_cpu_()\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/storage.py:297\u001B[0m, in \u001B[0;36m_share_memory_lock_protected.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;66;03m# If we acquired the storage lock here and we're done working on it\u001B[39;00m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;66;03m# we can now release it and free the entry.\u001B[39;00m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m to_free \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    302\u001B[0m         \u001B[38;5;66;03m# Ensure that the cdata from the storage didn't change and only\u001B[39;00m\n\u001B[1;32m    303\u001B[0m         \u001B[38;5;66;03m# the data_ptr did.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/storage.py:334\u001B[0m, in \u001B[0;36mUntypedStorage._share_filename_cpu_\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;129m@_share_memory_lock_protected\u001B[39m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_share_filename_cpu_\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_share_filename_cpu_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: no response from torch_shm_manager at \"/home/biscuitbobby/Documents/Projects/semantic_kernel_test/venv/lib64/python3.11/site-packages/torch/bin/torch_shm_manager\""
     ]
    }
   ],
   "source": [
    "llm = CustomLLM(model_name=\"petals-team/StableBeluga2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:04:10.766646659Z",
     "start_time": "2023-11-01T20:04:08.301063710Z"
    }
   },
   "id": "58f374be103b4abc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "# Create the LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-01T20:04:10.761634843Z"
    }
   },
   "id": "778dbe0dfbf6a645"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate a response\n",
    "question = input(\"query: \")\n",
    "response = llm_chain.run(question)\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-01T20:04:10.762992838Z"
    }
   },
   "id": "d8c20aa49e6d0013"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
